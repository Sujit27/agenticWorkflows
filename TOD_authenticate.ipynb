{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujit/agntic_workflow/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3508: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List, Literal, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-authorized-someplace-95\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSchema(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system_task = \"\"\"Your job is to gather information from the user and authenticate.\n",
    "\n",
    "You should obtain the following authentication fields from them:\n",
    "\n",
    "1. policy number\n",
    "2. last name\n",
    "3. date of birth\n",
    "\n",
    "Ask the user for authentication fields. \n",
    "If the use does not provide value for a field after repeated requests, let them know you would not be able to proceed further without it.\n",
    "If the use tries to engage them in any other conversation, bring them to the task of authenticating themselves in a polite and humorous way.\n",
    "\n",
    "ONLY OFTER you are able to get all the 3 authentication fields from the user, call the relevant tool.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_state_tracker(messages):\n",
    "    return [SystemMessage(content=prompt_system_task)] + messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UserStoryCriteria(BaseModel):\n",
    "#     \"\"\"Instructions on how to prompt the LLM.\"\"\"\n",
    "#     policyNumber: str\n",
    "#     fullName: str\n",
    "#     dateOfBirth: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuthenticationProfile(BaseModel):\n",
    "    \"\"\"Information about authentication fields\"\"\"\n",
    "    policy_number: str = Field(default=None, description=\"The policy number of the user\")\n",
    "    last_name: str = Field(default=None, description=\"The last name of the user\")\n",
    "    date_of_birth: str = Field(default=None, description=\"The date of birth of the user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseFormatter(BaseModel):\n",
    "    \"\"\"Always use this tool to structure the output\"\"\"\n",
    "    answer: bool = Field(description=\"True or False depending if user authentication was successful or not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = {\"policy_number\":\"0123456789\",\"last_name\":\"Sahoo\",\"date_of_birth\":\"27 Dec 1990\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_to_collect_info = llm.bind_tools([AuthenticationProfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_to_authenticate = llm.bind_tools([ResponseFormatter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_with_tool = llm.with_structured_output(schema=AuthenticationProfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(StateSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(state: StateSchema):\n",
    "    \"\"\"\n",
    "    talk_to_user node function, adds the prompt_system_task to the messages,\n",
    "    calls the LLM and returns the response\n",
    "    \"\"\"\n",
    "    messages = domain_state_tracker(state[\"messages\"])\n",
    "    response = llm_to_collect_info.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a1a00dbcb90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"talk_to_user\", call_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a1a00dbcb90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, \"talk_to_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a1a00dbcb90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalize_dialogue(state: StateSchema):\n",
    "    \"\"\"\n",
    "    Add a tool message to the history so the graph can see that it`s time to autheticate\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Prompt generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "workflow.add_node(\"finalize_dialogue\", finalize_dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a1a00dbcb90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate_user_story = \"\"\"Based on the following extracted fields from the user and the actual field values from database,/\n",
    " authenticate the user by providing True or False in output:\n",
    "\n",
    "extracted fields: {reqs}\n",
    "\n",
    "actual fields: {user_info}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt_to_generate_user_story(messages: list):\n",
    "    tool_call = None\n",
    "    other_msgs = []\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage) and m.tool_calls: #tool_calls is from the OpenAI API\n",
    "            tool_call = m.tool_calls[0][\"args\"]\n",
    "        elif isinstance(m, ToolMessage):\n",
    "            continue\n",
    "        elif tool_call is not None:\n",
    "            other_msgs.append(m)\n",
    "    return [SystemMessage(content=prompt_generate_user_story.format(reqs=tool_call,user_info=user_info))] + other_msgs\n",
    "\n",
    "\n",
    "def call_model_to_generate_user_story(state):\n",
    "    messages = build_prompt_to_generate_user_story(state[\"messages\"])\n",
    "    response = llm_to_authenticate.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "workflow.add_node(\"authenticate_user\", call_model_to_generate_user_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a1a00dbcb90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_next_action(state) -> Literal[\"finalize_dialogue\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"finalize_dialogue\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "workflow.add_conditional_edges(\"talk_to_user\", define_next_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7a1a00dbcb90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"finalize_dialogue\", \"authenticate_user\")\n",
    "workflow.add_edge(\"authenticate_user\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "It looks like you've provided your policy number and last name, but I need to confirm your date of birth in the format of day, month, and year. Could you please provide it again?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for providing the information. Let's proceed with the authentication.\n",
      "\n",
      "I'll use the following details:\n",
      "- Policy Number: 0123456789\n",
      "- Last Name: Sahoo\n",
      "- Date of Birth: December 27, 1991\n",
      "\n",
      "Let's get you authenticated!\n",
      "Tool Calls:\n",
      "  AuthenticationProfile (call_fW1PSjMOtC15ZKToxbyfrWnj)\n",
      " Call ID: call_fW1PSjMOtC15ZKToxbyfrWnj\n",
      "  Args:\n",
      "    policy_number: 0123456789\n",
      "    last_name: Sahoo\n",
      "    date_of_birth: December 27, 1991\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Prompt generated!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ResponseFormatter (call_XWD33ivDgWGNiIwAL4cgPfW8)\n",
      " Call ID: call_XWD33ivDgWGNiIwAL4cgPfW8\n",
      "  Args:\n",
      "    answer: False\n",
      "User NOT Authenticated!\n"
     ]
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    user = input(\"User (q/Q to quit): \")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"User NOT Authenticated!\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in graph.stream({\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"):\n",
    "        # print(output)\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if last_message.tool_calls:\n",
    "        if last_message.tool_calls[0]['args']['answer'] == True:\n",
    "            print(\"User Authenticated!\")\n",
    "        elif last_message.tool_calls[0]['args']['answer'] == False:\n",
    "            print(\"User NOT Authenticated!\")\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agntic_workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
