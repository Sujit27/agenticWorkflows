{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujit/agntic_workflow/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from typing import List, Literal, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\"\n",
    "os.environ['LANGSMITH_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-authorized-someplace-95\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSchema(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_system_task = \"\"\"Your job is to gather information from the user about the User Story they need to create.\n",
    "\n",
    "You should obtain the following information from them:\n",
    "\n",
    "- Objective: the goal of the user story. should be concrete enough to be developed in 2 weeks.\n",
    "- Success criteria the sucess criteria of the user story\n",
    "- Plan_of_execution: the plan of execution of the initiative\n",
    "- Deliverables: the deliverables of the initiative\n",
    "\n",
    "If you are not able to discern this info, ask them to clarify! Do not attempt to wildly guess. \n",
    "Whenever the user responds to one of the criteria, evaluate if it is detailed enough to be a criterion of a User Story. If not, ask questions to help the user better detail the criterion.\n",
    "Do not overwhelm the user with too many questions at once; ask for the information you need in a way that they do not have to write much in each response. \n",
    "Always remind them that if they do not know how to answer something, you can help them.\n",
    "\n",
    "After you are able to discern all the information, call the relevant tool.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_state_tracker(messages):\n",
    "    return [SystemMessage(content=prompt_system_task)] + messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserStoryCriteria(BaseModel):\n",
    "    \"\"\"Instructions on how to prompt the LLM.\"\"\"\n",
    "    objective: str\n",
    "    success_criteria: str\n",
    "    plan_of_execution: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool = llm.bind_tools([UserStoryCriteria])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(StateSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(state: StateSchema):\n",
    "    \"\"\"\n",
    "    talk_to_user node function, adds the prompt_system_task to the messages,\n",
    "    calls the LLM and returns the response\n",
    "    \"\"\"\n",
    "    messages = domain_state_tracker(state[\"messages\"])\n",
    "    response = llm_with_tool.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x78969f994e60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"talk_to_user\", call_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x78969f994e60>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(START, \"talk_to_user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x78969f994e60>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def finalize_dialogue(state: StateSchema):\n",
    "    \"\"\"\n",
    "    Add a tool message to the history so the graph can see that it`s time to create the user story\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            ToolMessage(\n",
    "                content=\"Prompt generated!\",\n",
    "                tool_call_id=state[\"messages\"][-1].tool_calls[0][\"id\"],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "workflow.add_node(\"finalize_dialogue\", finalize_dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x78969f994e60>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate_user_story = \"\"\"Based on the following requirements, write a good user story:\n",
    "\n",
    "{reqs}\"\"\"\n",
    "\n",
    "def build_prompt_to_generate_user_story(messages: list):\n",
    "    tool_call = None\n",
    "    other_msgs = []\n",
    "    for m in messages:\n",
    "        if isinstance(m, AIMessage) and m.tool_calls: #tool_calls is from the OpenAI API\n",
    "            tool_call = m.tool_calls[0][\"args\"]\n",
    "        elif isinstance(m, ToolMessage):\n",
    "            continue\n",
    "        elif tool_call is not None:\n",
    "            other_msgs.append(m)\n",
    "    return [SystemMessage(content=prompt_generate_user_story.format(reqs=tool_call))] + other_msgs\n",
    "\n",
    "\n",
    "def call_model_to_generate_user_story(state):\n",
    "    messages = build_prompt_to_generate_user_story(state[\"messages\"])\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "workflow.add_node(\"create_user_story\", call_model_to_generate_user_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x78969f994e60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def define_next_action(state) -> Literal[\"finalize_dialogue\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if isinstance(messages[-1], AIMessage) and messages[-1].tool_calls:\n",
    "        return \"finalize_dialogue\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "workflow.add_conditional_edges(\"talk_to_user\", define_next_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x78969f994e60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_edge(\"finalize_dialogue\", \"create_user_story\")\n",
    "workflow.add_edge(\"create_user_story\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'talk_to_user': {'messages': [AIMessage(content='Hello! How can I assist you today? Are you looking to create a User Story?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 274, 'total_tokens': 294, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-df5afff6-1d04-4fcd-9921-d85499605701-0', usage_metadata={'input_tokens': 274, 'output_tokens': 20, 'total_tokens': 294, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today? Are you looking to create a User Story?\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Alright! If there's anything else you need help with, feel free to let me know.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 301, 'total_tokens': 321, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-53fb20f8-4d48-4499-abbc-a02ba3e9bc56-0', usage_metadata={'input_tokens': 301, 'output_tokens': 20, 'total_tokens': 321, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Alright! If there's anything else you need help with, feel free to let me know.\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Great! Let's get started on creating your User Story. \\n\\nFirst, could you tell me the objective of the user story? It should be a goal that is concrete enough to be developed within two weeks.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 337, 'total_tokens': 380, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-5a8a4b75-9da6-475d-a625-ab8cedf9644c-0', usage_metadata={'input_tokens': 337, 'output_tokens': 43, 'total_tokens': 380, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! Let's get started on creating your User Story. \n",
      "\n",
      "First, could you tell me the objective of the user story? It should be a goal that is concrete enough to be developed within two weeks.\n",
      "{'talk_to_user': {'messages': [AIMessage(content='That sounds like an interesting project! To make sure we have a clear objective, could you specify what specific functionality or feature the conversational bot should demonstrate in the banking domain? For example, should it handle customer inquiries, process transactions, or provide financial advice?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 396, 'total_tokens': 449, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-f70c39a3-9338-42e6-bba3-2786a697b2a5-0', usage_metadata={'input_tokens': 396, 'output_tokens': 53, 'total_tokens': 449, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like an interesting project! To make sure we have a clear objective, could you specify what specific functionality or feature the conversational bot should demonstrate in the banking domain? For example, should it handle customer inquiries, process transactions, or provide financial advice?\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Got it! The objective is to create a demo of a conversational bot in the banking domain. \\n\\nNext, let's define the success criteria. What specific outcomes or results will indicate that this user story has been successfully completed? For example, should the bot be able to handle a certain number of inquiries, or should it demonstrate specific banking functionalities?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 458, 'total_tokens': 528, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-db63d79c-1469-440c-9336-19a1cde22bfd-0', usage_metadata={'input_tokens': 458, 'output_tokens': 70, 'total_tokens': 528, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! The objective is to create a demo of a conversational bot in the banking domain. \n",
      "\n",
      "Next, let's define the success criteria. What specific outcomes or results will indicate that this user story has been successfully completed? For example, should the bot be able to handle a certain number of inquiries, or should it demonstrate specific banking functionalities?\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Great! The success criteria are that the bot should be able to greet the user, authenticate them, and provide the status of an existing ticket.\\n\\nNow, let's move on to the plan of execution. How do you plan to develop and implement this demo? Do you have any specific steps or technologies in mind that you'll be using? If you're unsure, I can help you brainstorm some ideas.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 547, 'total_tokens': 627, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-cfe62324-d780-45f2-97b0-a60e1f75f61d-0', usage_metadata={'input_tokens': 547, 'output_tokens': 80, 'total_tokens': 627, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! The success criteria are that the bot should be able to greet the user, authenticate them, and provide the status of an existing ticket.\n",
      "\n",
      "Now, let's move on to the plan of execution. How do you plan to develop and implement this demo? Do you have any specific steps or technologies in mind that you'll be using? If you're unsure, I can help you brainstorm some ideas.\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Sure! Here are some steps and technologies you might consider for the plan of execution:\\n\\n1. **Define Requirements**: Clearly outline the requirements for the bot, including greeting, authentication, and ticket status retrieval.\\n\\n2. **Choose a Platform**: Decide on a platform or framework for building the bot. Options include:\\n   - **Dialogflow**: A Google service for building conversational interfaces.\\n   - **Microsoft Bot Framework**: A comprehensive framework for building bots.\\n   - **Rasa**: An open-source machine learning framework for automated text and voice-based conversations.\\n\\n3. **Design Conversation Flow**: Map out the conversation flow, including how the bot will greet users, authenticate them, and retrieve ticket status.\\n\\n4. **Develop Authentication Module**: Implement a secure authentication mechanism. This could involve integrating with existing banking authentication systems.\\n\\n5. **Integrate Ticketing System**: Connect the bot to the existing ticketing system to fetch and display ticket status.\\n\\n6. **Testing**: Conduct thorough testing to ensure the bot handles conversations smoothly and securely.\\n\\n7. **Feedback and Iteration**: Gather feedback from stakeholders and make necessary adjustments.\\n\\nDoes this plan align with your vision, or is there anything specific you'd like to add or modify?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 636, 'total_tokens': 890, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-4146c397-e867-46c7-8c01-46c08ed85880-0', usage_metadata={'input_tokens': 636, 'output_tokens': 254, 'total_tokens': 890, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure! Here are some steps and technologies you might consider for the plan of execution:\n",
      "\n",
      "1. **Define Requirements**: Clearly outline the requirements for the bot, including greeting, authentication, and ticket status retrieval.\n",
      "\n",
      "2. **Choose a Platform**: Decide on a platform or framework for building the bot. Options include:\n",
      "   - **Dialogflow**: A Google service for building conversational interfaces.\n",
      "   - **Microsoft Bot Framework**: A comprehensive framework for building bots.\n",
      "   - **Rasa**: An open-source machine learning framework for automated text and voice-based conversations.\n",
      "\n",
      "3. **Design Conversation Flow**: Map out the conversation flow, including how the bot will greet users, authenticate them, and retrieve ticket status.\n",
      "\n",
      "4. **Develop Authentication Module**: Implement a secure authentication mechanism. This could involve integrating with existing banking authentication systems.\n",
      "\n",
      "5. **Integrate Ticketing System**: Connect the bot to the existing ticketing system to fetch and display ticket status.\n",
      "\n",
      "6. **Testing**: Conduct thorough testing to ensure the bot handles conversations smoothly and securely.\n",
      "\n",
      "7. **Feedback and Iteration**: Gather feedback from stakeholders and make necessary adjustments.\n",
      "\n",
      "Does this plan align with your vision, or is there anything specific you'd like to add or modify?\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Great! We have a solid plan of execution. \\n\\nFinally, let's define the deliverables. What specific outputs or artifacts will be produced as part of this user story? For example, a working demo of the bot, documentation, or a presentation for stakeholders?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 897, 'total_tokens': 951, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None}, id='run-a8bbb677-fab3-4634-bf8b-507d2ba33c13-0', usage_metadata={'input_tokens': 897, 'output_tokens': 54, 'total_tokens': 951, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! We have a solid plan of execution. \n",
      "\n",
      "Finally, let's define the deliverables. What specific outputs or artifacts will be produced as part of this user story? For example, a working demo of the bot, documentation, or a presentation for stakeholders?\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"Perfect! The deliverable will include analytics on the number of times the bot is able to solve the use case, either partially or completely.\\n\\nHere's a summary of what we have for the User Story:\\n\\n- **Objective**: Create a demo of a conversational bot in the banking domain.\\n- **Success Criteria**: The bot should greet the user, authenticate them, and provide the status of an existing ticket.\\n- **Plan of Execution**: \\n  - Define requirements.\\n  - Choose a platform (e.g., Dialogflow, Microsoft Bot Framework, Rasa).\\n  - Design conversation flow.\\n  - Develop authentication module.\\n  - Integrate with the ticketing system.\\n  - Conduct testing.\\n  - Gather feedback and iterate.\\n- **Deliverables**: Analytics on the number of times the bot solves the use case, either partially or completely.\\n\\nI'll now proceed to create the User Story with these criteria.\", additional_kwargs={'tool_calls': [{'id': 'call_6KnQW2QHcVCRAbN2JltIUpyK', 'function': {'arguments': '{\"objective\":\"Create a demo of a conversational bot in the banking domain.\",\"success_criteria\":\"The bot should greet the user, authenticate them, and provide the status of an existing ticket.\",\"plan_of_execution\":\"Define requirements, choose a platform (e.g., Dialogflow, Microsoft Bot Framework, Rasa), design conversation flow, develop authentication module, integrate with the ticketing system, conduct testing, gather feedback and iterate.\"}', 'name': 'UserStoryCriteria'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 283, 'prompt_tokens': 975, 'total_tokens': 1258, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4757cb7a-309e-4772-bc66-3dda1ba9f5e9-0', tool_calls=[{'name': 'UserStoryCriteria', 'args': {'objective': 'Create a demo of a conversational bot in the banking domain.', 'success_criteria': 'The bot should greet the user, authenticate them, and provide the status of an existing ticket.', 'plan_of_execution': 'Define requirements, choose a platform (e.g., Dialogflow, Microsoft Bot Framework, Rasa), design conversation flow, develop authentication module, integrate with the ticketing system, conduct testing, gather feedback and iterate.'}, 'id': 'call_6KnQW2QHcVCRAbN2JltIUpyK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 975, 'output_tokens': 283, 'total_tokens': 1258, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Perfect! The deliverable will include analytics on the number of times the bot is able to solve the use case, either partially or completely.\n",
      "\n",
      "Here's a summary of what we have for the User Story:\n",
      "\n",
      "- **Objective**: Create a demo of a conversational bot in the banking domain.\n",
      "- **Success Criteria**: The bot should greet the user, authenticate them, and provide the status of an existing ticket.\n",
      "- **Plan of Execution**: \n",
      "  - Define requirements.\n",
      "  - Choose a platform (e.g., Dialogflow, Microsoft Bot Framework, Rasa).\n",
      "  - Design conversation flow.\n",
      "  - Develop authentication module.\n",
      "  - Integrate with the ticketing system.\n",
      "  - Conduct testing.\n",
      "  - Gather feedback and iterate.\n",
      "- **Deliverables**: Analytics on the number of times the bot solves the use case, either partially or completely.\n",
      "\n",
      "I'll now proceed to create the User Story with these criteria.\n",
      "Tool Calls:\n",
      "  UserStoryCriteria (call_6KnQW2QHcVCRAbN2JltIUpyK)\n",
      " Call ID: call_6KnQW2QHcVCRAbN2JltIUpyK\n",
      "  Args:\n",
      "    objective: Create a demo of a conversational bot in the banking domain.\n",
      "    success_criteria: The bot should greet the user, authenticate them, and provide the status of an existing ticket.\n",
      "    plan_of_execution: Define requirements, choose a platform (e.g., Dialogflow, Microsoft Bot Framework, Rasa), design conversation flow, develop authentication module, integrate with the ticketing system, conduct testing, gather feedback and iterate.\n",
      "{'finalize_dialogue': {'messages': [ToolMessage(content='Prompt generated!', id='78b45927-cc1b-4bab-aff3-fa0bea42438b', tool_call_id='call_6KnQW2QHcVCRAbN2JltIUpyK')]}}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Prompt generated!\n",
      "{'create_user_story': {'messages': [AIMessage(content=\"**User Story:**\\n\\nAs a customer of the bank, I want to interact with a conversational bot that can assist me with my banking inquiries, so that I can efficiently manage my banking needs without the need to visit a branch or call customer service.\\n\\n**Acceptance Criteria:**\\n\\n1. The bot should initiate the conversation by greeting the user in a friendly and professional manner.\\n2. The bot must authenticate the user securely by verifying their identity through a series of questions or a secure login process.\\n3. Once authenticated, the bot should be able to access the bank's ticketing system and provide the user with the current status of any existing support tickets they have.\\n4. The bot should be available on multiple platforms, such as the bank's website and mobile app, ensuring accessibility for all users.\\n5. The conversation flow should be intuitive and easy to follow, with clear prompts and responses.\\n6. The bot should handle errors gracefully, providing helpful messages and options to the user if something goes wrong.\\n7. The system should be tested thoroughly to ensure reliability and gather user feedback for continuous improvement.\\n\\n**Plan of Execution:**\\n\\n1. Define detailed requirements for the bot's functionality and user interactions.\\n2. Choose a suitable platform for development, such as Dialogflow, Microsoft Bot Framework, or Rasa, based on the bank's infrastructure and needs.\\n3. Design a conversation flow that covers greeting, authentication, and ticket status inquiry, ensuring a seamless user experience.\\n4. Develop a robust authentication module that securely verifies user identity.\\n5. Integrate the bot with the bank's existing ticketing system to fetch and display ticket status.\\n6. Conduct comprehensive testing to identify and fix any issues, ensuring the bot meets all success criteria.\\n7. Gather user feedback post-launch to identify areas for improvement and iterate on the bot's design and functionality.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 370, 'prompt_tokens': 110, 'total_tokens': 480, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-18e9027e-1fdb-4567-8b18-7c623b57aae5-0', usage_metadata={'input_tokens': 110, 'output_tokens': 370, 'total_tokens': 480, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "**User Story:**\n",
      "\n",
      "As a customer of the bank, I want to interact with a conversational bot that can assist me with my banking inquiries, so that I can efficiently manage my banking needs without the need to visit a branch or call customer service.\n",
      "\n",
      "**Acceptance Criteria:**\n",
      "\n",
      "1. The bot should initiate the conversation by greeting the user in a friendly and professional manner.\n",
      "2. The bot must authenticate the user securely by verifying their identity through a series of questions or a secure login process.\n",
      "3. Once authenticated, the bot should be able to access the bank's ticketing system and provide the user with the current status of any existing support tickets they have.\n",
      "4. The bot should be available on multiple platforms, such as the bank's website and mobile app, ensuring accessibility for all users.\n",
      "5. The conversation flow should be intuitive and easy to follow, with clear prompts and responses.\n",
      "6. The bot should handle errors gracefully, providing helpful messages and options to the user if something goes wrong.\n",
      "7. The system should be tested thoroughly to ensure reliability and gather user feedback for continuous improvement.\n",
      "\n",
      "**Plan of Execution:**\n",
      "\n",
      "1. Define detailed requirements for the bot's functionality and user interactions.\n",
      "2. Choose a suitable platform for development, such as Dialogflow, Microsoft Bot Framework, or Rasa, based on the bank's infrastructure and needs.\n",
      "3. Design a conversation flow that covers greeting, authentication, and ticket status inquiry, ensuring a seamless user experience.\n",
      "4. Develop a robust authentication module that securely verifies user identity.\n",
      "5. Integrate the bot with the bank's existing ticketing system to fetch and display ticket status.\n",
      "6. Conduct comprehensive testing to identify and fix any issues, ensuring the bot meets all success criteria.\n",
      "7. Gather user feedback post-launch to identify areas for improvement and iterate on the bot's design and functionality.\n",
      "User story created!\n",
      "{'talk_to_user': {'messages': [AIMessage(content=\"You're welcome! If you have any more questions or need further assistance, feel free to reach out. Good luck with your project!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 1649, 'total_tokens': 1677, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None}, id='run-c79c3dad-8ae0-4fc3-81c2-5ea69fa5f7e4-0', usage_metadata={'input_tokens': 1649, 'output_tokens': 28, 'total_tokens': 1677, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're welcome! If you have any more questions or need further assistance, feel free to reach out. Good luck with your project!\n",
      "AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    user = input(\"User (q/Q to quit): \")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    output = None\n",
    "    for output in graph.stream({\"messages\": [HumanMessage(content=user)]}, config=config, stream_mode=\"updates\"):\n",
    "        print(output)\n",
    "        last_message = next(iter(output.values()))[\"messages\"][-1]\n",
    "        last_message.pretty_print()\n",
    "\n",
    "    if output and \"create_user_story\" in output:\n",
    "        print(\"User story created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agntic_workflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
